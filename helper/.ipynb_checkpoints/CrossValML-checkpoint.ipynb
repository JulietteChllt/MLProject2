{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1843cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pre_processing import get_pre_process_data\n",
    "from pre_processing import get_pre_process_data_test\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier, LinearRegression\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7edde0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(full=False,run_processing = False): \n",
    "    if run_processing : \n",
    "        tweet_pos, tweet_neg, tweet_test = desired_preprocessing(full,'preprocessing_pos.txt','preprocessing_neg.txt','preprocessing_test.txt')\n",
    "    else : \n",
    "        if full : \n",
    "            #change\n",
    "            path_pos = '../Resources/preprocessing_pos_full.txt'\n",
    "            path_neg = '../Resources/preprocessing_neg_full.txt'\n",
    "        else : \n",
    "            path_pos = '../Resources/preprocessing_pos1.txt'\n",
    "            path_neg = '../Resources/preprocessing_neg1.txt'\n",
    "        \n",
    "        path_test = '../Resources/preprocessing_test1.txt'\n",
    "    \n",
    "        tweet_pos = [tweet.rstrip('\\n') for tweet in open(path_pos)]\n",
    "        tweet_neg = [tweet.rstrip('\\n') for tweet in open(path_neg)]\n",
    "        tweet_test = [tweet.rstrip('\\n') for tweet in open(path_test)]\n",
    "    \n",
    "    data_test = pd.DataFrame({\"tweet\": tweet_test})  \n",
    "    data_pos = pd.DataFrame({\"tweet\": tweet_pos,\"sentiment\": np.ones(len(tweet_pos))})\n",
    "    data_neg = pd.DataFrame({ \"tweet\": tweet_neg, \"sentiment\": np.zeros(len(tweet_neg)) })\n",
    "    \n",
    "    data_train = pd.concat([data_pos, data_neg],axis=0).reset_index().drop(columns=['index'])\n",
    "\n",
    "    data_train = data_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aef75d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train(X,y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6de6c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train,data_test = to_dataset()\n",
    "X_train, X_val, y_train, y_val = split_train(data_train.tweet,data_train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e862960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23821     ahh long story going hear soon right laught go...\n",
       "134809                       laught alright spam spam later\n",
       "141838                             not want weekend already\n",
       "115299                               oh slide flamingo love\n",
       "130763                          ok thankyou consecutivestop\n",
       "                                ...                        \n",
       "119879    light audio cd sure alien laser gun princess c...\n",
       "103694    laught making collage laught big mistake leavi...\n",
       "131932                        always speak booty love booty\n",
       "146867              very true tamara see using stuff learnt\n",
       "121958    assimilation intensive workshop cd set turn fi...\n",
       "Name: tweet, Length: 137836, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20d3eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(clf, X, y):\n",
    "    \"\"\"\n",
    "    Returns the model for clf trained\n",
    "    INPUT:\n",
    "        clf :                     - The classifier to train\n",
    "        X : Multidimensional list - The traning features\n",
    "        y : list                  - The traning results\n",
    "    OUTPUT:\n",
    "        Returns the model trained\n",
    "    \"\"\"\n",
    "    tvec = TfidfVectorizer().set_params(\n",
    "        stop_words=None, max_features=100000, ngram_range=(1, 3))\n",
    "\n",
    "    model_pipeline = Pipeline([('vectorizer', tvec), ('classifier', clf)])\n",
    "    model_pipeline.fit(X, y)\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83aa0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(model, X_test) : \n",
    "    return model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71a6c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y,y_val):\n",
    "    return (y==y_val).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5aeb7723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result for Logistic Regression\n",
      "LogisticRegression()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 79.60%\n",
      "train and test time: 18.93s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Linear SVC\n",
      "LinearSVC()\n",
      "accuracy score: 78.46%\n",
      "train and test time: 11.16s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for LinearSVC with L1-based feature selection\n",
      "Pipeline(steps=[('feature_selection',\n",
      "                 SelectFromModel(estimator=LinearSVC(dual=False,\n",
      "                                                     penalty='l1'))),\n",
      "                ('classification', LinearSVC())])\n",
      "accuracy score: 78.61%\n",
      "train and test time: 14.01s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Multinomial NB\n",
      "MultinomialNB()\n",
      "accuracy score: 77.55%\n",
      "train and test time: 8.96s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Bernoulli NB\n",
      "BernoulliNB()\n",
      "accuracy score: 75.37%\n",
      "train and test time: 9.69s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Ridge Classifier\n",
      "RidgeClassifier()\n",
      "accuracy score: 79.11%\n",
      "train and test time: 9.63s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for AdaBoost\n",
      "AdaBoostClassifier()\n",
      "accuracy score: 71.39%\n",
      "train and test time: 28.48s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Perceptron\n",
      "Perceptron()\n",
      "accuracy score: 73.32%\n",
      "train and test time: 9.73s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Passive-Aggresive\n",
      "PassiveAggressiveClassifier()\n",
      "accuracy score: 73.10%\n",
      "train and test time: 13.99s\n",
      "--------------------------------------------------------------------------------\n",
      "Validation result for Nearest Centroid\n",
      "NearestCentroid()\n",
      "accuracy score: 72.90%\n",
      "train and test time: 9.83s\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score \n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "\n",
    "def acc_summary(pipeline, x_train, y_train, x_test, y_test):\n",
    "    t0 = time()\n",
    "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
    "    y_pred = sentiment_fit.predict(x_test)\n",
    "    train_test_time = time() - t0\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
    "    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n",
    "    print(\"-\"*80)\n",
    "    return accuracy, train_test_time\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer()\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "names = [\"Logistic Regression\", \"Linear SVC\", \"LinearSVC with L1-based feature selection\",\"Multinomial NB\", \n",
    "         \"Bernoulli NB\", \"Ridge Classifier\", \"AdaBoost\", \"Perceptron\",\"Passive-Aggresive\", \"Nearest Centroid\"]\n",
    "classifiers = [\n",
    "    LogisticRegression(),\n",
    "    LinearSVC(),\n",
    "    Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    RidgeClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    Perceptron(),\n",
    "    PassiveAggressiveClassifier(),\n",
    "    NearestCentroid()\n",
    "    ]\n",
    "zipped_clf = zip(names,classifiers)\n",
    "\n",
    "tvec = TfidfVectorizer()\n",
    "def classifier_comparator(vectorizer=tvec, n_features=100000, stop_words=None, ngram_range=(1, 1), classifier=zipped_clf):\n",
    "    result = []\n",
    "    vectorizer.set_params(stop_words=stop_words, max_features=n_features, ngram_range=ngram_range)\n",
    "    for n,c in classifier:\n",
    "        checker_pipeline = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', c.set_params(max_iter=n))\n",
    "        ])\n",
    "        print(\"Validation result for {}\".format(n))\n",
    "        print (c)\n",
    "        clf_acc,tt_time = acc_summary(checker_pipeline, X_train, y_train, X_val, y_val)\n",
    "        result.append((n,clf_acc,tt_time))\n",
    "    return result\n",
    "\n",
    "trigram_result = classifier_comparator(n_features=100000,ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15620c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
